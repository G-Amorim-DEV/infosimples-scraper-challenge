
# ü¶Ü Infosimples - Desafio T√©cnico (Web Scraping)

Este reposit√≥rio cont√©m a solu√ß√£o para o desafio t√©cnico proposto pela **Infosimples**, com foco na constru√ß√£o de um scraper web em **Python**.

## üìå Sobre o Desafio

O objetivo do desafio era acessar uma p√°gina de produto de e-commerce fict√≠cia e coletar automaticamente todas as suas informa√ß√µes relevantes. A p√°gina simulada foi:

üîó https://infosimples.com/vagas/desafio/commercia/product.html

A tarefa consistia em:

- Acessar a p√°gina usando HTTP GET
- Fazer o parsing do HTML da p√°gina
- Extrair os seguintes dados:
  - T√≠tulo do produto
  - Marca
  - Categorias
  - Descri√ß√£o
  - Varia√ß√µes do produto (nome, pre√ßo atual, pre√ßo antigo e disponibilidade)
  - Propriedades t√©cnicas do produto (ex: material, cor, peso, origem, etc.)
  - Avalia√ß√µes de clientes (nome, data, nota e coment√°rio)
  - Nota m√©dia das avalia√ß√µes
  - URL da p√°gina

O resultado final deveria ser salvo em um arquivo `produto.json`, com todos os dados estruturados no formato solicitado.

## üìÇ Arquivos no Reposit√≥rio

- `Take_Home_Coding_Challenge.py`: Script Python respons√°vel por acessar a p√°gina, extrair os dados e salv√°-los em JSON.
- `produto.json`: Resultado da execu√ß√£o do scraper com os dados extra√≠dos.

> ‚ö†Ô∏è O arquivo PDF original com a descri√ß√£o do desafio **n√£o ser√° inclu√≠do** neste reposit√≥rio, mas todas as informa√ß√µes relevantes foram descritas aqui.

## üß∞ Tecnologias Utilizadas

- Python 3
- BeautifulSoup4
- Requests
- JSON

## ‚ñ∂Ô∏è Como Executar

1. Instale as depend√™ncias:

```bash
pip install requests beautifulsoup4
```

2. Execute o script:

```bash
python Take_Home_Coding_Challenge.py
```

3. O arquivo `produto.json` ser√° gerado com os dados extra√≠dos da p√°gina.

---

# ü¶Ü Infosimples - Take-Home Coding Challenge (Web Scraping)

This repository contains the solution to the take-home coding challenge proposed by **Infosimples**, focusing on building a **Python** web scraper.

## üìå About the Challenge

The goal of the challenge was to automatically access and extract structured data from a simulated e-commerce product page:

üîó https://infosimples.com/vagas/desafio/commercia/product.html

The task included:

- Making an HTTP GET request to the page  
- Parsing the HTML content  
- Extracting the following information:
  - Product title
  - Brand
  - Categories
  - Description
  - Product variations (name, current price, old price, availability)
  - Product properties (e.g., material, color, weight, origin, etc.)
  - Customer reviews (name, date, score, and review text)
  - Average review score
  - Page URL

The extracted information was saved in a structured `produto.json` file.

## üìÇ Files in the Repository

- `Take_Home_Coding_Challenge.py`: Python script that performs scraping and writes the data to JSON.
- `produto.json`: Final result containing the extracted product data.

> ‚ö†Ô∏è The original PDF with the full challenge description is **not included** in this repository. All relevant details have been explained here.

## üß∞ Technologies Used

- Python 3
- BeautifulSoup4
- Requests
- JSON

## ‚ñ∂Ô∏è How to Run

1. Install the dependencies:

```bash
pip install requests beautifulsoup4
```

2. Run the script:

```bash
python Take_Home_Coding_Challenge.py
```

3. The `produto.json` file will be created with the extracted data.
